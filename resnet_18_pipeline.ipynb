{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This is the set up cell that checks for the environment and sets up the resnet model.",
   "id": "5f7385177330ebe5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Print system information first\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name()}\")\n",
    "\n",
    "# Initialize device without clearing cache\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def setup_model():\n",
    "    \"\"\"\n",
    "    Creates a ResNet18 model with careful initialization\n",
    "    \"\"\"\n",
    "    print(\"\\nInitializing model...\")\n",
    "    try:\n",
    "        # Force model to initialize on CPU\n",
    "        with torch.device('cpu'):\n",
    "            # Load the model\n",
    "            model = models.resnet18(pretrained=True)\n",
    "            # Modify the final layer\n",
    "            model.fc = nn.Linear(model.fc.in_features, 40)\n",
    "            print(\"Model initialized successfully on CPU\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error in model setup: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "this is the DataLoader class",
   "id": "2552cb4b0911ad33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Stanford40Dataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "\n",
    "        # Load action classes\n",
    "        with open(os.path.join(root_dir, 'ImageSplits/actions.txt'), 'r') as f:\n",
    "            self.classes = [line.split()[0] for line in f.readlines()[1:]]\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "\n",
    "        # Build list of all images and their corresponding actions\n",
    "        self.images = []\n",
    "        missing_xmls = []  # Keep track of missing XML files\n",
    "\n",
    "        for action in self.classes:\n",
    "            split_file = os.path.join(root_dir, f'ImageSplits/{action}_{split}.txt')\n",
    "            with open(split_file, 'r') as f:\n",
    "                image_ids = [os.path.splitext(line.strip())[0] for line in f.readlines()]\n",
    "\n",
    "                # Check XML existence for each image before adding it\n",
    "                for img_id in image_ids:\n",
    "                    xml_path = os.path.join(root_dir, 'XMLAnnotations', f'{img_id}.xml')\n",
    "                    if os.path.exists(xml_path):\n",
    "                        self.images.append((action, img_id))\n",
    "                    else:\n",
    "                        missing_xmls.append((action, img_id))\n",
    "\n",
    "        # Print summary of missing XML files\n",
    "        if missing_xmls:\n",
    "            print(f\"Warning: Found {len(missing_xmls)} images without XML annotations\")\n",
    "            print(\"First few missing XMLs:\")\n",
    "            for action, img_id in missing_xmls[:5]:\n",
    "                print(f\"  - Missing XML for {action}: {img_id}\")\n",
    "            print(f\"Total images retained: {len(self.images)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        action, img_id = self.images[idx]\n",
    "\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.root_dir, 'JPEGImages', f'{img_id}.jpg')\n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(f\"Image file not found: {img_path}\")\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Load bounding box (we know XML exists because we checked in __init__)\n",
    "        xml_path = os.path.join(self.root_dir, 'XMLAnnotations', f'{img_id}.xml')\n",
    "        try:\n",
    "            tree = ET.parse(xml_path)\n",
    "            root = tree.getroot()\n",
    "            bbox = root.find('object/bndbox')\n",
    "\n",
    "            if bbox is None:\n",
    "                raise ValueError(f\"No bounding box found in {xml_path}\")\n",
    "\n",
    "            box = [\n",
    "                float(bbox.find('xmin').text),\n",
    "                float(bbox.find('ymin').text),\n",
    "                float(bbox.find('xmax').text),\n",
    "                float(bbox.find('ymax').text)\n",
    "            ]\n",
    "\n",
    "            # Validate box coordinates\n",
    "            if not (0 <= box[0] <= box[2] and 0 <= box[1] <= box[3]):\n",
    "                raise ValueError(f\"Invalid box coordinates in {xml_path}: {box}\")\n",
    "\n",
    "        except ET.ParseError as e:\n",
    "            raise ValueError(f\"XML parsing error in {xml_path}: {str(e)}\")\n",
    "\n",
    "        # Original image dimensions for scaling\n",
    "        orig_width, orig_height = image.size\n",
    "\n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "            # Scale bounding box coordinates\n",
    "            scale_x = 224.0 / orig_width\n",
    "            scale_y = 224.0 / orig_height\n",
    "            box = [\n",
    "                box[0] * scale_x,\n",
    "                box[1] * scale_y,\n",
    "                box[2] * scale_x,\n",
    "                box[3] * scale_y\n",
    "            ]\n",
    "\n",
    "        return image, self.class_to_idx[action], torch.tensor(box)\n",
    "\n",
    "# Usage example:\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = Stanford40Dataset('/content/drive/MyDrive/Stanford40', split='train', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "def inspect_dataset(dataset):\n",
    "\n",
    "    print(\"\\n1. Number of Images:\")\n",
    "    print(f\"Total images: {len(dataset)}\")\n",
    "\n",
    "    # Check class distribution\n",
    "    print(\"\\n5. Checking Class Distribution:\")\n",
    "    class_counts = {}\n",
    "    for action, _ in dataset.images:\n",
    "        class_counts[action] = class_counts.get(action, 0) + 1\n",
    "    print(\"Images per class (first 5 classes):\")\n",
    "    for class_name, count in list(class_counts.items()):\n",
    "        print(f\"{class_name}: {count} images\")\n",
    "\n",
    "# Run the inspection\n",
    "inspect_dataset(dataset)"
   ],
   "id": "5e09017448d564e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "this is the test for checking wether the bounding boxes scale and descale works",
   "id": "fca19f97825795a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torchvision.transforms as T\n",
    "\n",
    "def show_images_with_boxes(dataset, num_images=5):\n",
    "    \"\"\"\n",
    "    Display random images from the dataset with their bounding boxes and class labels.\n",
    "\n",
    "    Args:\n",
    "        dataset: The Stanford40Dataset instance\n",
    "        num_images: Number of random images to display\n",
    "    \"\"\"\n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(20, 4))\n",
    "\n",
    "    # Get random indices\n",
    "    total_images = len(dataset)\n",
    "    random_indices = random.sample(range(total_images), num_images)\n",
    "\n",
    "    # Helper function to denormalize the image\n",
    "    denormalize = T.Compose([\n",
    "        T.Normalize(mean=[0, 0, 0], std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "        T.Normalize(mean=[-0.485, -0.456, -0.406], std=[1, 1, 1]),\n",
    "    ])\n",
    "\n",
    "    for idx, ax in zip(random_indices, axes):\n",
    "        # Get image and its data\n",
    "        image, class_idx, bbox = dataset[idx]\n",
    "\n",
    "        # Denormalize the image\n",
    "        image = denormalize(image)\n",
    "\n",
    "        # Convert to numpy for displaying\n",
    "        img_np = image.permute(1, 2, 0).numpy()\n",
    "        img_np = np.clip(img_np, 0, 1)  # Clip values to valid range\n",
    "\n",
    "        # Display the image\n",
    "        ax.imshow(img_np)\n",
    "\n",
    "        # Draw the bounding box\n",
    "        x_min, y_min, x_max, y_max = bbox.numpy()\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "\n",
    "        # Create rectangle patch\n",
    "        rect = plt.Rectangle((x_min, y_min), width, height,\n",
    "                           fill=False, color='red', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Add class label\n",
    "        class_name = [k for k, v in dataset.class_to_idx.items() if v == class_idx][0]\n",
    "        ax.set_title(f\"Class: {class_name}\")\n",
    "\n",
    "        # Remove axes ticks\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Use the function\n",
    "show_images_with_boxes(dataset)"
   ],
   "id": "1aad082fdd84a685"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "those 2 cells were actualy used in training and starting the procees",
   "id": "5054b544ba18e357"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch with real-time monitoring\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_start_time = time.time()\n",
    "\n",
    "    for batch_idx, (inputs, labels, _) in enumerate(dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Batch statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # Real-time monitoring (every 10 batches)\n",
    "        if batch_idx % 10 == 0:\n",
    "            batch_time = time.time() - batch_start_time\n",
    "            current_loss = running_loss / (batch_idx + 1)\n",
    "            current_acc = 100. * correct / total\n",
    "\n",
    "            print(f'Batch {batch_idx}/{len(dataloader)} | '\n",
    "                  f'Time: {batch_time:.2f}s | '\n",
    "                  f'Loss: {current_loss:.4f} | '\n",
    "                  f'Acc: {current_acc:.2f}% | '\n",
    "                  f'GPU Mem: {torch.cuda.memory_allocated()/1024**2:.0f}MB')\n",
    "\n",
    "            batch_start_time = time.time()\n",
    "\n",
    "    return running_loss / len(dataloader), 100. * correct / total\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, device, num_epochs=10, save_dir='model_checkpoints'):\n",
    "    \"\"\"\n",
    "    Simplified training pipeline without validation\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    training_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # Training phase\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "\n",
    "        # Save training history\n",
    "        history = {\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'lr': optimizer.param_groups[0]['lr']\n",
    "        }\n",
    "        training_history.append(history)\n",
    "\n",
    "        # Save model periodically\n",
    "        if (epoch + 1) % 5 == 0:  # Save every 5 epochs\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': train_loss,\n",
    "                'training_history': training_history\n",
    "            }, os.path.join(save_dir, f'model_epoch_{epoch+1}.pth'))\n",
    "\n",
    "        # Epoch summary\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        print(f'\\nEpoch {epoch+1} Summary:')\n",
    "        print(f'Time: {epoch_time:.2f}s')\n",
    "        print(f'Loss: {train_loss:.4f}')\n",
    "        print(f'Accuracy: {train_acc:.2f}%')\n",
    "        print(f'Learning Rate: {optimizer.param_groups[0][\"lr\"]}')\n",
    "        print('-' * 50)\n",
    "\n",
    "    return training_history"
   ],
   "id": "73f3e19e64487967"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "import torch.cuda as cuda\n",
    "\n",
    "# Set up data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Print dataset information\n",
    "print(\"Setting up dataset and model...\")\n",
    "train_dataset = Stanford40Dataset('/content/drive/MyDrive/Stanford40', split='train', transform=transform)\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "\n",
    "# Create dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Setup for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory allocated: {torch.cuda.memory_allocated(0)/1024**2:.2f} MB\")\n",
    "    print(f\"Memory cached: {torch.cuda.memory_reserved(0)/1024**2:.2f} MB\")\n",
    "\n",
    "model = setup_model().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Calculate total parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nModel parameters:\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Print training configuration\n",
    "print(\"\\nTraining configuration:\")\n",
    "print(f\"Batch size: 32\")\n",
    "print(f\"Initial learning rate: 0.001\")\n",
    "print(f\"Optimizer: Adam\")\n",
    "print(f\"Loss function: CrossEntropyLoss\")\n",
    "\n",
    "# Start training\n",
    "print(\"\\nStarting training...\")\n",
    "start_time = time.time()\n",
    "start_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"Start time: {start_datetime}\")\n",
    "\n",
    "training_history = train_model(model, train_loader, criterion, optimizer, device)\n",
    "\n",
    "# Print training summary\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "hours = int(elapsed_time // 3600)\n",
    "minutes = int((elapsed_time % 3600) // 60)\n",
    "seconds = int(elapsed_time % 60)\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(f\"Total training time: {hours}h {minutes}m {seconds}s\")\n",
    "print(f\"Final training loss: {training_history[-1]['train_loss']:.4f}\")\n",
    "print(f\"Final training accuracy: {training_history[-1]['train_acc']:.2f}%\")\n",
    "\n",
    "# If using GPU, print final memory usage\n",
    "if device.type == 'cuda':\n",
    "    print(f\"\\nFinal GPU memory usage:\")\n",
    "    print(f\"Memory allocated: {torch.cuda.memory_allocated(0)/1024**2:.2f} MB\")\n",
    "    print(f\"Memory cached: {torch.cuda.memory_reserved(0)/1024**2:.2f} MB\")\n",
    "\n",
    "# Save final training summary\n",
    "summary_file = os.path.join('model_checkpoints', 'training_summary.txt')\n",
    "with open(summary_file, 'w') as f:\n",
    "    f.write(f\"Training Summary\\n\")\n",
    "    f.write(f\"===============\\n\")\n",
    "    f.write(f\"Start time: {start_datetime}\\n\")\n",
    "    f.write(f\"Training duration: {hours}h {minutes}m {seconds}s\\n\")\n",
    "    f.write(f\"Training samples: {len(train_dataset)}\\n\")\n",
    "    f.write(f\"Final training loss: {training_history[-1]['train_loss']:.4f}\\n\")\n",
    "    f.write(f\"Final training accuracy: {training_history[-1]['train_acc']:.2f}%\\n\")"
   ],
   "id": "de7f765ade12e5f4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Validation\n",
   "id": "cb962f3a2094f7b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def validate_model(model, test_loader, criterion, device, classes):\n",
    "    \"\"\"\n",
    "    Validates the model on test data and returns detailed metrics\n",
    "    \n",
    "    Args:\n",
    "        model: The trained PyTorch model\n",
    "        test_loader: DataLoader for test data\n",
    "        criterion: Loss function\n",
    "        device: Device to run validation on\n",
    "        classes: List of class names\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing various validation metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    class_correct = [0] * len(classes)\n",
    "    class_total = [0] * len(classes)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, boxes in tqdm(test_loader, desc=\"Validating\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Accumulate loss\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Get predictions\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            # Accumulate predictions for confusion matrix\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # Per-class accuracy\n",
    "            for label, pred in zip(labels, predicted):\n",
    "                if label == pred:\n",
    "                    class_correct[label] += 1\n",
    "                class_total[label] += 1\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    # Per-class accuracies\n",
    "    class_accuracies = {}\n",
    "    for i in range(len(classes)):\n",
    "        if class_total[i] > 0:\n",
    "            class_accuracies[classes[i]] = 100 * class_correct[i] / class_total[i]\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(all_labels, all_preds, \n",
    "                                 target_names=classes, \n",
    "                                 output_dict=True)\n",
    "    \n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'class_accuracies': class_accuracies,\n",
    "        'confusion_matrix': cm,\n",
    "        'classification_report': report,\n",
    "        'predictions': all_preds,\n",
    "        'true_labels': all_labels\n",
    "    }\n",
    "\n",
    "def plot_validation_results(results, classes, save_dir='validation_results'):\n",
    "    \"\"\"\n",
    "    Creates and saves visualization plots for validation results\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Plot confusion matrix\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sns.heatmap(results['confusion_matrix'], \n",
    "                xticklabels=classes,\n",
    "                yticklabels=classes,\n",
    "                annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_dir}/confusion_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Plot per-class accuracies\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    accuracies = list(results['class_accuracies'].values())\n",
    "    class_names = list(results['class_accuracies'].keys())\n",
    "    plt.bar(class_names, accuracies)\n",
    "    plt.title('Per-Class Accuracies')\n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_dir}/class_accuracies.png')\n",
    "    plt.close()\n",
    "\n",
    "def save_validation_report(results, save_dir='validation_results'):\n",
    "    \"\"\"\n",
    "    Saves validation results to a detailed report file\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    with open(f'{save_dir}/validation_report.txt', 'w') as f:\n",
    "        f.write(\"Model Validation Report\\n\")\n",
    "        f.write(\"=====================\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Overall Accuracy: {results['accuracy']:.2f}%\\n\")\n",
    "        f.write(f\"Average Loss: {results['loss']:.4f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"Per-Class Performance:\\n\")\n",
    "        f.write(\"--------------------\\n\")\n",
    "        for class_name, accuracy in results['class_accuracies'].items():\n",
    "            f.write(f\"{class_name}: {accuracy:.2f}%\\n\")\n",
    "        \n",
    "        f.write(\"\\nDetailed Classification Report:\\n\")\n",
    "        f.write(\"----------------------------\\n\")\n",
    "        report = results['classification_report']\n",
    "        for class_name, metrics in report.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                f.write(f\"\\n{class_name}:\\n\")\n",
    "                f.write(f\"  Precision: {metrics['precision']:.3f}\\n\")\n",
    "                f.write(f\"  Recall: {metrics['recall']:.3f}\\n\")\n",
    "                f.write(f\"  F1-score: {metrics['f1-score']:.3f}\\n\")\n",
    "                f.write(f\"  Support: {metrics['support']}\\n\")\n",
    "\n",
    "# Main validation pipeline\n",
    "def run_validation(model_path, test_dataset, device, batch_size=32):\n",
    "    \"\"\"\n",
    "    Runs the complete validation pipeline\n",
    "    \"\"\"\n",
    "    # Load the trained model\n",
    "    model = setup_model().to(device)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Create test dataloader\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Set up criterion\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Run validation\n",
    "    print(\"Starting validation...\")\n",
    "    results = validate_model(model, test_loader, criterion, device, test_dataset.classes)\n",
    "    \n",
    "    # Create visualizations and save results\n",
    "    print(\"Generating validation reports and visualizations...\")\n",
    "    plot_validation_results(results, test_dataset.classes)\n",
    "    save_validation_report(results)\n",
    "    \n",
    "    print(f\"\\nValidation completed!\")\n",
    "    print(f\"Overall Accuracy: {results['accuracy']:.2f}%\")\n",
    "    print(f\"Average Loss: {results['loss']:.4f}\")\n",
    "    print(\"\\nDetailed results have been saved to the validation_results directory.\")\n",
    "    \n",
    "    return results"
   ],
   "id": "458cfc7b04766ceb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_dataset = Stanford40Dataset('/content/drive/MyDrive/Stanford40', split='test', transform=transform)\n",
    "model_path = '/content/model_epoch_10.pth'\n",
    "validation_results = run_validation(model_path, test_dataset, device)"
   ],
   "id": "2c3de785676bf38c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Validation completed!\n",
    "Overall Accuracy: 51.54%\n",
    "Average Loss: 2.1094"
   ],
   "id": "40c4aead867ab6eb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
